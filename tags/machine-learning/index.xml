<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning on Moyan&#39;s Blog</title>
    <link>https://mmy12580.github.io/tags/machine-learning/</link>
    <description>Recent content in machine learning on Moyan&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Apr 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://mmy12580.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Optimizer matters the most!</title>
      <link>https://mmy12580.github.io/posts/optimizers/</link>
      <pubDate>Wed, 15 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://mmy12580.github.io/posts/optimizers/</guid>
      <description>Introduction As a researcher, most time of my job is to build an appropriate AI prototype for specific tasks. To achieve a satisfactory result, an expected large amount of work i.e tuning hyper-parameters, balancing data, augmentation etc are needed. The most deterministic component of deep learning practice is choosing the appropriate optimization algorithms, which directly affect the training speed and the final predictive performance. To date, there is no theory that adequately explains how to make this choice.</description>
    </item>
    
    <item>
      <title>NlPer路线图</title>
      <link>https://mmy12580.github.io/posts/nlp-roadmap/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mmy12580.github.io/posts/nlp-roadmap/</guid>
      <description>这篇blog属于专门给喜爱NLP的童鞋们准备的。路线图（roadmap）包含了从基础的 $\color{blue}{概率学}$ 和 $\color{blue}{统计学}$，到$\color{blue}{机器学习}$，到$\color{blue}{文本挖掘}$，到 关键字之间的关系可以用模棱两可的方式解释，因为它们以语义思维导图的格式表示。请只将重点放在方格中的关键字上，并认为它们是学习必不可少的部分。自然语言处理 (natural language processing, aka., NLP)。本篇属于转载，原地址在reddit的讨论区中。
注意事项  $\color{red}{关键字}$之间的关系可以用模棱两可的方式解释，因为它们以语义思维导图的格式表示。请只将重点放在方格中的关键字上，并认为它们是学习必不可少的部分。 路线图仅供于参考，并不能直接代替你理解关键词与其之间的关系  概率学与统计 (Probability &amp;amp; Statistics) 机器学习 (Machine Learning) 文本挖掘 (Text Mining) 自然语言处理 (NLP) Reference $[1]$ ratsgo&amp;rsquo;s blog for textmining, ratsgo/ratsgo.github.io
$[2]$ (한국어) 텍스트 마이닝을 위한 공부거리들, lovit/textmining-tutorial
$[3]$ Christopher Bishop(2006). Pattern Recognition and Machine Learning
$[4]$ Young, T., Hazarika, D., Poria, S., &amp;amp; Cambria, E. (2017). Recent Trends in Deep Learning Based Natural Language Processing. arXiv preprint arXiv:1708.</description>
    </item>
    
    <item>
      <title>A quick summary for imbalanced data</title>
      <link>https://mmy12580.github.io/posts/imbalanced_learn_summary/</link>
      <pubDate>Tue, 18 Jun 2019 11:28:17 -0400</pubDate>
      
      <guid>https://mmy12580.github.io/posts/imbalanced_learn_summary/</guid>
      <description>Data imbalance occurs when the sample size in the data classes are unevenly distributed. Such situation is encountered in many applications in industry. Sometimes, it could be extremely imbalanced e.g click-through rate prediction, fraud detection, or cancer diagnosis etc. Most of machine learning techniques work well with balanced training data but they face challenges when the dataset classes are imbalanced. In such situation, classification methods tend to be biased towards the majority class.</description>
    </item>
    
  </channel>
</rss>