<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nlp on Moyan&#39;s Website</title>
    <link>https://mmy12580.github.io/tags/nlp/</link>
    <description>Recent content in nlp on Moyan&#39;s Website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://mmy12580.github.io/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Normalization in Deep Learning</title>
      <link>https://mmy12580.github.io/posts/normalization_for_dl/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mmy12580.github.io/posts/normalization_for_dl/</guid>
      <description>Introduction $\color{blue}{\text{Batch Normalization (BN)}}$ has been treated as one of the standard &amp;ldquo;plug-in&amp;rdquo; tool to deep neural networks since its first release. It is been proved to be very helpful in a tons of machine learning applications due to its several advantages as followings:
 faster training higher learning rate easier initialization more activations support deeper but simpler architecture regularization  Algorithms:
\begin{align*} &amp;amp;{\text { Input: Values of } x \text { over a mini-batch: } \mathcal{B}= {x_{1 \ldots m}}} \newline &amp;amp;{\text { Output: } {y_{i}=\mathrm{B} \mathrm{N}_{\gamma, \beta} (x_{i})}} \newline &amp;amp;{\mu_{\mathcal{B}} \leftarrow \frac{1}{m} \sum_{i=1}^{m} x_{i} \qquad \text { // min-batch mean}} \newline &amp;amp;{\sigma_{\mathcal{B}}^{2} \leftarrow \frac{1}{m} \sum_{i=1}^{m}\left(x_{i}-\mu_{\mathcal{B}}\right)^{2} \qquad \text { // mini-batch variance }} \newline &amp;amp;{\hat{x}_{i} \leftarrow \frac{x_{i}-\mu_{\mathcal{B}}}{\sqrt{\sigma_{\mathcal{B}}^{2}+\epsilon}} \qquad \text { // normalize }} \newline &amp;amp;{y_{i} \leftarrow \gamma \widehat{x}_{i}+\beta \equiv \mathrm{B} \mathrm{N}_{\gamma, \beta}\left(x_{i}\right) \qquad \text { // scale and shift }} \end{align*}</description>
    </item>
    
  </channel>
</rss>