<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Moyan&#39;s Website</title>
    <link>https://mmy12580.github.io/posts/</link>
    <description>Recent content in Posts on Moyan&#39;s Website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Jun 2019 11:28:17 -0400</lastBuildDate>
    
	<atom:link href="https://mmy12580.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A quick summary for imbalanced data</title>
      <link>https://mmy12580.github.io/posts/imbalanced_learn_summary/</link>
      <pubDate>Tue, 18 Jun 2019 11:28:17 -0400</pubDate>
      
      <guid>https://mmy12580.github.io/posts/imbalanced_learn_summary/</guid>
      <description>Data imbalance occurs when the sample size in the data classes are unevenly distributed. Such situation is encountered in many applications in industry. Sometimes, it could be extremely imbalanced e.g click-through rate prediction, fraud detection, or cancer diagnosis etc. Most of machine learning techniques work well with balanced training data but they face challenges when the dataset classes are imbalanced. In such situation, classification methods tend to be biased towards the majority class.</description>
    </item>
    
    <item>
      <title>Training on Large Batches</title>
      <link>https://mmy12580.github.io/posts/training_nn_on_large_batches/</link>
      <pubDate>Mon, 17 Jun 2019 12:21:44 -0400</pubDate>
      
      <guid>https://mmy12580.github.io/posts/training_nn_on_large_batches/</guid>
      <description>According to Sebastian Ruder&amp;rsquo;s blog post, the ImageNet moment of NLP has arrived. Especially, models like e.g BERT, ELMO, UlMFIT,Open-GPT, Transformer-XL have become the main stream choice of most downstream NLP tasks. However, it is still quite difficult to conduct a transfer learning task from a pre-training model such as 345 millions parameter open-gpt2 with a large batch say 256. Certainly, if your NLP tasks is with small datasets, and you are able to use batch_size = 8, and wait for 2-4 hours to do it, that is none of the cases I am talking about here.</description>
    </item>
    
    <item>
      <title>å¤šçº¿ç¨‹è¿˜æ˜¯å¤šè¿›ç¨‹?</title>
      <link>https://mmy12580.github.io/posts/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%BF%98%E6%98%AF%E5%A4%9A%E8%BF%9B%E7%A8%8B/</link>
      <pubDate>Thu, 23 May 2019 10:41:23 -0400</pubDate>
      
      <guid>https://mmy12580.github.io/posts/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%BF%98%E6%98%AF%E5%A4%9A%E8%BF%9B%E7%A8%8B/</guid>
      <description>Introduction å› ä¸ºæˆ‘æ˜¯pythonçš„ä½¿ç”¨è€…ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘åªèƒ½é€šè¿‡æˆ‘å¯¹äºæˆ‘å·¥ä½œä¸­çš„ä¸€äº›ç»éªŒï¼Œæå‡ºä¸€äº›åœ¨pythonä¸Šä»€ä¹ˆæ—¶å€™ä½¿ç”¨å¤šçº¿ç¨‹(Multi-Threading)è¿˜æ˜¯å¤šè¿›ç¨‹(Multi-Processing)ã€‚å¯¹äºå…¶ä»–ä¸“ä¸šäººå£«ï¼Œè¿™é‡Œç¨å¾®å¤šå¤šåŒ…æ¶µä¸€ä¸‹ï¼Œæ¯•ç«Ÿæˆ‘ä¹Ÿéç§‘ç­å‡ºèº«ã€‚ä½†æ˜¯å¯¹äºdata scientist, machine learning engineer, æˆ‘ä¸ªäººä¼šç»™å‡ºä¸€äº›è¯¦ç»†çš„æ¯”è¾ƒï¼Œä»¥å¸®åŠ©å¤§å®¶ä»¥ååœ¨designè‡ªå·±çš„pipelineã€‚
å½“å¤§å®¶è€ƒè™‘åœ¨CPUä¸Šè¿›è¡Œå¹¶è¡Œè®¡ç®—ï¼ˆparallel computing)çš„æ—¶å€™ï¼Œä¸€èˆ¬Google: how to do parallel computing in python? ä¸€èˆ¬ä¼šå‡ºç°çš„æ˜¯å…¸å‹çš„ä¸¤ä¸ªpackages, e.g multiprocessing ä»¥åŠ concurent.futuresã€‚å¯¹äºå…·ä½“æ€ä¹ˆä½¿ç”¨ï¼Œä¸€èˆ¬åœ¨stack overflowçš„ç­”æ¡ˆï¼Œå¤§å®¶ä¸€copy, æ”¹æˆä¸€ä¸ªfunction, ç„¶åç›´æ¥å¥—ç”¨å°±ç»“æŸäº†ã€‚å¯¹äºæ•°æ®ä¸å¤§ï¼Œå¹¶ä¸”ç›¸å¯¹ç›´æ¥çš„è¿ç®—ä¸Š e.g exp, powç­‰ï¼Œç»“æœæ¯”for loopå¿«å¾ˆå¤šå€å°±å¤Ÿäº†ã€‚æ²¡é”™ï¼Œä½†æ˜¯æœ¬æ–‡æƒ³è®¨è®ºçš„æ˜¯ï¼Œå¦‚æœæ˜¯ä½ çš„ ML pipelineï¼Œè¿™æ—¶å€™åº”è¯¥æ€ä¹ˆç”¨ï¼Ÿä¹Ÿæ˜¯æ”¹ä¸€ä¸ªfunctionï¼Œç›´æ¥å¥—ç”¨åŒ…ï¼Œå°±å¯ä»¥ä¿è¯é€Ÿåº¦ï¼Œä¿è¯è´¨é‡äº†å—ï¼Ÿæ‰€ä»¥ï¼Œè¿™æ‰ç‰¹åœ°æ€»ç»“äº†ä¸€ä¸ªblog, ä¾›è‡ªå·±å’Œå¤§å®¶å‚è€ƒã€‚
æˆ‘ä»¬é€šè¿‡é—®é¢˜æ¥ä¸€æ­¥æ­¥è¿›è¡Œæ¯”è¾ƒï¼Œåœ¨æ–‡ç« æœ«ç«¯ï¼Œä¼šæä¾›ç»“è®ºã€‚
å¤šçº¿ç¨‹=å¤šè¿›ç¨‹ï¼Ÿ ç­”æ¡ˆå¾ˆæ˜æ˜¾ï¼Œæ˜¯é”™è¯¯çš„ã€‚ è¿™é‡Œï¼Œæˆ‘é€šè¿‡ä¸€äº›ç®€å•çš„çš„ä»£ç ï¼Œæ¥å®ç°æ¯”è¾ƒã€‚ä»¥ä¸‹ä»£ç æˆ‘å»ºç«‹äº†ä¸‰ç§è®¡ç®—çš„æ–¹æ³•ï¼Œfor loop, å¤šçº¿ç¨‹ï¼Œä»¥åŠå¤šè¿›ç¨‹ä»¥åŠç”»å›¾æ¯”è¾ƒå¤šè¿›ç¨‹å’Œå¤šçº¿ç¨‹çš„å‡½æ•°ã€‚
import time import numpy as np from matplotlib import pyplot as plt from concurrent.futures import ProcessPoolExecutor from concurrent.futures import ThreadPoolExecutor # naive for loop def naive_add(x): start = time.time() count = 0 for i in range(10**8): count += i stop = time.</description>
    </item>
    
    <item>
      <title>Leafyå¼€æºä¸­æ–‡åˆ†è¯æ¨¡å‹(Transformer)</title>
      <link>https://mmy12580.github.io/posts/leafy%E5%BC%80%E6%BA%90%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 22 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mmy12580.github.io/posts/leafy%E5%BC%80%E6%BA%90%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%A8%A1%E5%9E%8B/</guid>
      <description>ç®€ä»‹ ä¸ºäº†ç»™ç”¨æˆ·æœ‰æ›´å¥½çš„NLPäº§å“ä½“éªŒï¼Œä»¥åŠåç«¯æ‹¥æœ‰æ›´å¥½çš„æ–‡æœ¬æœç´¢å¼•æ“å¤„ç†æ–¹æ¡ˆï¼Œç‰¹åœ°åšæ¥ä¸€å¥—å®Œæ•´çš„NLPç³»ç»Ÿï¼ŒåŒ…æ‹¬äº†åˆ†è¯(tokenziation), åºåˆ—æ ‡æ³¨(Sequential Labeling)çš„å…¶ä»–åŠŸèƒ½ e.g POS taggingå’Œå®ä½“è¯†åˆ«(NER)ï¼Œä»¥åŠå…¶ä½™ä¸‹æ¸¸ä»»åŠ¡(downstream tasks) ä¾‹å¦‚ï¼Œæ–‡æœ¬æœç´¢ï¼ˆInformation Retrieval)å’Œæ™ºèƒ½å®¢æœï¼ˆQ&amp;amp;A)ã€‚
ä¸ºä»€ä¹ˆè¦åšåˆ†è¯ï¼Ÿ æœ€æ ‡å‡†çš„ç­”æ¡ˆï¼š
åœ¨ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œè¯æ˜¯æœ€å°çš„èƒ½å¤Ÿç‹¬ç«‹æ´»åŠ¨çš„æœ‰æ„ä¹‰çš„è¯­è¨€æˆåˆ†ã€‚æ±‰è¯­æ˜¯ä»¥å­—ä¸ºåŸºæœ¬ä¹¦å†™å•ä½ï¼Œè¯è¯­ä¹‹é—´æ²¡æœ‰æ˜æ˜¾çš„åŒºåˆ†æ ‡è®°ï¼Œå› æ­¤è¿›è¡Œä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†é€šå¸¸æ˜¯å…ˆå°†æ±‰è¯­æ–‡æœ¬ä¸­çš„å­—ç¬¦ä¸²åˆ‡åˆ†æˆåˆç†çš„è¯è¯­åºåˆ—ï¼Œç„¶åå†åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œå…¶å®ƒåˆ†æå¤„ç†ã€‚ä¸­æ–‡åˆ†è¯æ˜¯ä¸­æ–‡ä¿¡æ¯å¤„ç†çš„ä¸€ä¸ªåŸºç¡€ç¯èŠ‚ï¼Œå·²è¢«å¹¿æ³›åº”ç”¨äºä¸­æ–‡æ–‡æœ¬å¤„ç†ã€ä¿¡æ¯æå–ã€æ–‡æœ¬æŒ–æ˜ç­‰åº”ç”¨ä¸­ã€‚
ç®€å•æ¥è¯´ï¼Œè¯æ˜¯æ–‡æœ¬å…·æœ‰æ„ä¹‰çš„æœ€å°å•ä½ï¼Œè€Œä¸”å¥½çš„è¯ï¼Œå¯ä»¥è®©ä¸€äº›ä¸‹æ¸¸ä»»åŠ¡æ›´ç›´æ¥æ–¹ä¾¿ã€‚ç›®å‰ä¸­å›½æœ‰å¾ˆå¤šçš„åˆ†è¯å·¥å…·ï¼Œæœ€è‘—åçš„ä¾‹å¦‚jieba, hanlp, ä»¥åŠåŒ—å¤§ä»Šå¹´æœ€æ–°çš„ç ”ç©¶æˆæœpkusegç­‰ç­‰ã€‚éœ€è¦çŸ¥é“ä¸­æ–‡åˆ†è¯è¯¦æƒ…å†…å®¹å¹¶ä¸”å¸¦æœ‰åŸºç¡€ä»£ç ä½¿ç”¨çš„ï¼Œè¿™é‡Œæœ‰ä¸€ä»½å¾ˆå¥½çš„åšå®¢å†…å®¹ã€‚ é‚£ä¹ˆé—®é¢˜æ¥äº†ï¼Œæ—¢ç„¶æœ‰è¿™ä¹ˆå¤šä¼˜ç§€çš„åˆ†è¯å·¥å…·ï¼Œä¸ºä»€ä¹ˆè¦åšè‡ªå·±çš„åˆ†è¯ï¼Ÿ æˆ‘æ€»ç»“äº†ä¸‹ï¼Œæœ‰ä¸‰ä¸ªç†ç”±ï¼
 æ³›åŒ–èƒ½åŠ›ä¸å¤Ÿå¼ºï¼ˆQuestionable Interpretablity): åˆ†è¯çš„éš¾ç‚¹æ˜¯æ­§ä¹‰ï¼Œè§„èŒƒï¼Œä»¥åŠæœªç™»å½•è¯è¯†åˆ«ã€‚ä¸åŒçš„æ–¹æ³•æœ‰ä¸åŒçš„ä¼˜ç¼ºç‚¹ï¼Œç›®å‰è¿˜æ²¡æœ‰ä¸€ä¸ªuniversally goodæ–¹æ³•ã€‚æœ‰ç»éªŒçš„NLPerï¼Œä¼šå‘ç°å¾ˆå¤šè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ”¾åˆ°ä¸€ä¸ªæ–°çš„domainé‡Œï¼Œæ¯”å¦‚æ–°é—»ï¼Œæ³•å¾‹ï¼ŒåŒ»è¯ï¼Œæ¨¡å‹çš„æ‰¿è½½åŠ›capacityä¸å¤Ÿå¤§ï¼Œä¸å…·æœ‰å¥½çš„æ³›åŒ–èƒ½åŠ› ä¸å…·æœ‰è§£é‡Šæ€§ï¼ˆnon-interpretabl): ç›®å‰çš„ä¸­æ–‡åˆ†è¯çš„ç›´æ¥åº”ç”¨ï¼Œæ›´å¤šæ˜¯ä½œä¸ºæœç´¢å¼•æ“ï¼Œæˆ–è€…æ˜¯ä½œä¸ºè®¸å¤šNLPä¸‹æ¸¸ä»»åŠ¡çš„é¢„å¤„ç†å·¥å…·ã€‚ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ /ç»Ÿè®¡å­¦ä¹ æ–¹æ³•å’Œä¸€äº›ç›®å‰å­˜åœ¨çš„æ·±åº¦å­¦ä¹ åˆ†è¯æ–¹æ³•å’Œå…¶ä»–çš„ä¸‹æ¸¸ä»»åŠ¡ï¼Œç»å¤§éƒ¨åˆ†æƒ…å†µæ˜¯ç‹¬ç«‹åˆ†å¼€è¿›è¡Œçš„ã€‚è¯­ä¹‰å„ç§è¯­è¨€å­¦ç‰¹å¾æ›´å¤šæ¥è‡ªäºæ— ç›‘ç£, è‡ªç›‘ç£ä¸ç›‘ç£å­¦ä¹ çš„ä»»åŠ¡ä¸­è·å¾—ï¼Œå¹¶å¯è§£é‡Šã€‚ ä¸å…·æœ‰å»¶å±•æ€§ (non-extendable): å—åˆ°äº†å¤šä»»åŠ¡å­¦ä¹ ï¼ˆmulti-task learningï¼‰çš„ç‰¹ç‚¹çš„å¯å‘ï¼Œpos tagggingå’Œname entity recognitionï¼Œè¿™ä¸¤ä¸ªä»»åŠ¡éå¸¸ç›¸ä¼¼ï¼ŒåŸºæœ¬ä¸Šåªæ˜¯ä¸åŒæ ‡ç­¾åŒ–ï¼Œæœ€ç»ˆå¥—ä¸€å±‚æ¡ä»¶éšæœºåœº(CRF)å·²è·å¾—joint probabilityçš„æœ€å¤§åŒ–ã€‚è¿™ç‚¹ï¼Œé€»è¾‘ä¸Šå¾ˆç±»ä¼¼äºå¤šæ ‡ç­¾å­¦ä¹ ï¼ˆmulti-label learning)ï¼Œä¾‹å¦‚ â€œæˆ‘å–œæ¬¢å°¤æ–‡å›¾æ–¯ä¿±ä¹éƒ¨â€ï¼Œ è€Œå°¤æ–‡å›¾æ–¯ä¿±ä¹éƒ¨é™¤äº†æ˜¯åè¯ï¼ˆpos tagging)ä¹‹å¤–ä¹Ÿæ˜¯ç‰¹æœ‰åè¯ï¼ˆentity)ã€‚ä½†æ˜¯åœ¨å­¦ä¹ çš„æ—¶å€™å› ä¸ºä½¿ç”¨çš„latentç‰¹å¾å¹¶ä¸å®Œå…¨ç›¸åŒä»¥åŠlatenç‰¹å¾çš„åˆ†å¸ƒä¸åŒ, æ‰€ä»¥å¤šæ ‡ç­¾å­¦ä¹ åœ¨è¡¨ç°ä¸Šå¹¶ä¸å¦‚å¤šä»»åŠ¡å­¦ä¹ ã€‚å½“ç„¶ï¼Œè¿™é‡Œè¿˜æœ‰å¦å¤–ä¸€ç§å­¦ä¹ æ–¹æ³•, è”åˆå­¦ä¹ ï¼ˆjoint modelling)ï¼Œé€»è¾‘ä¸Šä¹Ÿéå¸¸ç±»ä¼¼ï¼Œä¹Ÿæœ‰å¾ˆå¥½çš„resultï¼Œè¿™é‡Œæœ€é‡è¦çš„åŒºåˆ«å°±æ˜¯è”åˆå­¦ä¹ æ˜¯æŒ‡ç›¸ä¼¼åº¦é«˜çš„ä»»åŠ¡åŒæ—¶å­¦ä¹ ï¼Œ è€Œå¤šä»»åŠ¡å­¦ä¹ å¯ä»¥æ˜¯ä¸åŒä»»åŠ¡ï¼Œç›¸ä¼¼åº¦ä¹Ÿä¸ä¸€å®šè¦æ±‚é«˜ï¼Œå¹¶ä¸”å¯ä»¥æœ‰å…ˆåé¡ºåºçš„å­¦ä¹ æ–¹æ³•ã€‚è¿™é‡Œå‚è§ä¸€ä¸‹å¤§ç‰›Sebastian Ruderçš„Ph.D. thesis. è¿™ç§å¤šä»»åŠ¡å­¦ä¹ ï¼Œå¯ä»¥æˆä¸ºä¸€ä¸ªå®Œæ•´çš„ç«¯å¯¹ç«¯ç³»ç»Ÿ(end-to-end learning), è®©æˆ‘ä»¬æœ€ç»ˆèƒ½åœ¨å¤šé¢†åŸŸå¤šä»»åŠ¡ä¸‹å®Œæˆå¥½çš„ä»»åŠ¡ã€‚Facebookä¸­çš„XLMæˆåŠŸçš„æ­å»ºäº†è·¨è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡ä¸åŒçš„è¯­è¨€å»è·å¾—å½“ä¸‹è¯­è¨€çš„ä¸€äº›ç‰¹æ€§å’Œè§£å†³å½“ä¸‹è¯­è¨€ä¸­æŸä¸ªè¾ƒéš¾å­¦ä¹ çš„ä»»åŠ¡ï¼Œæ–‡ä¸­æåˆ°æœ€å¸¸ç”¨çš„é¡¹ç›®å³ä¸ºæœºå™¨ç¿»è¯‘ä»¥åŠæ–‡æœ¬åˆ†ç±»ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°†åˆ†è¯æ¨¡å‹é€šè¿‡è”åˆå­¦ä¹ å­¦æˆï¼Œå†é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ æ‰©å±•ï¼Œä»¥æä¾›æ›´ä¼˜ç§€çš„äººå·¥æ™ºèƒ½è§£å†³æ–¹æ¡ˆ  Literature: æ·±åº¦å­¦ä¹ ä¸­æ–‡åˆ†è¯ ç›®å‰ï¼Œæˆ‘èƒ½æ‰¾åˆ°çš„æ·±åº¦å­¦ä¹ ä¸­æ–‡åˆ†è¯æ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤å¤§ç±»ï¼Œç¬¬ä¸€ç§bi-LSTMçš„è¡ç”Ÿæ–¹æ³• e.g stacked bi-LSTMã€‚ç¬¬äºŒç§æ˜¯ç”¨unsupervised Embeddingå¥—bi-GRUæˆ–è€…bi-LSTMã€‚å…·ä½“çš„æ–¹æ³•ï¼Œåœ¨ä»¥ä¸‹é“¾æ¥ä¸­ï¼Œæ„Ÿå…´è¶£çš„æœ‹å‹å¯ä»¥è‡ªè¡Œä½“éªŒï¼š
 JointPS: Seq2Seq (Transition + LSTM) ç™¾åº¦çš„lac: char-embedding + bi-GRU Ownthinkçš„Jiaguè‡ªç„¶è¯­è¨€å¤„ç†å·¥å…· pywordSeg: BiLSTM + ELMo Neural Networks Incorporating Dictionaries for Chinese Word Segmentation: è·¨é¢†åŸŸå’ŒåŒé¢†åŸŸä¸­æ–‡åˆ†è¯  ä»¥ä¸Šæ¯ä¸€ç§æ–¹æ³•åœ¨è¯»è€…ä½ è‡ªå·±çš„æƒ…å†µé‡Œéƒ½æœ‰å¯èƒ½é€‚ç”¨ï¼Œä¹Ÿå–å†³äºä½ çš„éœ€æ±‚ï¼Œå¦‚æœåªæ˜¯æƒ³å•çº¯çš„åšä¸ªåˆ†è¯ï¼Œéœ€è¦ä¸€ä¸ªé«˜ç²¾åº¦çš„æ–¹æ³•ï¼Œä¼ ç»Ÿçš„ç»Ÿè®¡æ–¹æ³•å’Œæœºå™¨å­¦ä¹ æ–¹æ³•çš„æ¨¡å‹éƒ½å¾ˆå¾ˆå¥½ï¼Œè€Œä¸”ä¹Ÿå¯ä»¥è¿›è¡Œå¹¶è¡Œè¿ç®—è¾¾åˆ°é€Ÿåº¦éå¸¸å¿«çš„æ•ˆæœã€‚è€Œå¯¹äºLeafyçš„æƒ…å†µè€Œè¨€ï¼Œæˆ‘éœ€è¦ä¸€ç§å¯æ‰©å±•ï¼Œå¹¶ä¸”è®­ç»ƒæ—¶å€™å¯å¹¶è¡Œçš„æ¨¡å‹ï¼Œå¹¶ä¸”å¯¹æ¯”äºLSTMå’ŒRNNçš„ç‰¹ç‚¹ç›¸å¯¹æ›´æœ‰ä¼˜åŠ¿çš„æ–¹æ³•ï¼Œæˆ‘é€‰æ‹©äº†transformerã€‚æƒ³å…·ä½“äº†è§£transformerçš„è¯»è€…å¯ä»¥è¯»ä¸¤ç¯‡æ–‡ç« link1å’Œlink2ã€‚ ç®€å•æ¥è¯´ï¼Œ é€‰æ‹©transformeråŸå› ï¼Œå› ä¸ºå…¶ä¼˜ç‚¹</description>
    </item>
    
    <item>
      <title>Industrial Solution: FAISS</title>
      <link>https://mmy12580.github.io/posts/faiss_dev/</link>
      <pubDate>Sat, 02 Mar 2019 01:55:11 -0500</pubDate>
      
      <guid>https://mmy12580.github.io/posts/faiss_dev/</guid>
      <description>Intuition Imagine a case, you are developing a facial recognition algorithm for Canadian Custom. They would like to use it to detect suspects. The accuracy and speed are needed to track a person effciently. Let us say you have already tried your best to provide a promising performence of identifying every visitor, however, due to it is a vary large database (40 million population in Canada), searching a feature vector (extracted from a CNN model) over the huge databse can be very very time-consuming, and then it may not be as effective as you can.</description>
    </item>
    
    <item>
      <title>ç½‘ç«™æ­å»º:hugo&#43;github</title>
      <link>https://mmy12580.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugo&#43;github-page&#43;https/</link>
      <pubDate>Fri, 01 Mar 2019 11:27:28 -0500</pubDate>
      
      <guid>https://mmy12580.github.io/posts/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugo&#43;github-page&#43;https/</guid>
      <description>åˆè¡· ä¸ªäººç½‘ç«™è¿™ä¸ªäº‹æƒ…ï¼Œæƒ³å€’è…¾å¾ˆä¹…äº†ã€‚å¯æƒœä¸€ç›´è¢«å„ç§äº‹æƒ…ç»™å½±å“ï¼Œè¿‘æ¥æƒ³ç€ï¼Œè¿˜æ˜¯å¾—å‘ä¸€ä¸‹ç‹ ã€‚åœ¨2019å¹´å¹´åˆå€’è…¾ä¸€ä¸ªä¸ªäººç½‘ç«™ï¼ŒåŸå› å¾ˆç®€å•ï¼Œé«˜æ•ˆçš„åšåšç¬”è®°ï¼Œå‘è¡¨ä¸€äº›çœ‹æ³•ï¼Œå¸Œæœ›èƒ½å’Œæ›´å¤šäººäº¤æµï¼Œå­¦ä¹ ä»¥åŠæˆé•¿ã€‚Stay foolish, stay hungary! æœ¬æ–‡å°†ä»‹ç»å¦‚ä½•æ­é…Hugo + Github Pages + ä¸ªäººåŸŸåçš„æµç¨‹ã€‚å› ä¸ºæˆ‘æ˜¯ç”¨Macæ­å»ºçš„ï¼Œæ‰€ä»¥è¿™é‡Œçš„å‡†å¤‡å·¥ä½œå’Œå…·ä½“çš„æµç¨‹éƒ½åªåŒ…å«äº†å¦‚ä½•ç”¨Macæ­å»ºï¼ˆlinux å¤§åŒå°å¼‚)ã€‚è¿™é‡Œå¯¹windowsçš„ç«¥é‹å…ˆè¯´å£°æŠ±æ­‰äº†(ã‚·_ _)ã‚·ï¼Œå› ä¸ºæˆ‘å­¦ä»£ç å¼€å§‹æ²¡ç”¨è¿‡ğŸ˜…ã€‚å¯¹äºå†™ä»£ç çš„è¦æ±‚ï¼Œè¿™é‡Œå¹¶ä¸é«˜ï¼Œåªéœ€è¦ä½ å¯¹terminalä¼šç”¨ä¸€äº›å¸¸ç”¨çš„ä»£ç å°±å¯ä»¥äº†ï¼Œå½“ç„¶ï¼Œå…¶æœ€åŸºæœ¬çš„gitçš„ä»£ç è¿˜æ˜¯éœ€è¦çš„ e.g git clone, add, commit, pushè¿™äº› ã€‚è€Œå¯¹äºå®Œå…¨æ²¡å†™è¿‡ä»£ç çš„å°ç™½ï¼Œæœ‰ä¸€äº›ä¸œè¥¿ä¹Ÿåªèƒ½éº»çƒ¦ä½ ä»¬è‡ªå·±googleäº†ï¼Œæ¯”å¦‚å¦‚ä½•å»ºç«‹githubã€‚æˆ‘è¿™é‡Œä¼šæä¾›ä¸€äº›ç›¸å¯¹åº”çš„é“¾æ¥ï¼Œä»¥æ–¹ä¾¿ä½ åœ¨å»ºç«‹ç½‘ç«™æ—¶çš„æµç¨‹.
å‡†å¤‡å·¥ä½œ æ­£å¦‚æ ‡é¢˜æ‰€è¯´ï¼Œåªéœ€è¦å®‰è£…hugo, github page, ä»¥åŠhttpsä¿éšœç½‘ç«™å®‰å…¨å°±å¥½äº†.
ä¾èµ–ç¯å¢ƒï¼š  brew git hugo  å‰æœŸå®‰è£… å®‰è£…brew, å…ˆæ‰“å¼€spotlightè¾“å…¥terminal, ç„¶åå¤åˆ¶ä»¥ä¸‹ä»£ç 
/usr/bin/ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;  å®‰è£…åï¼Œå®‰è£…git
brew install git  å®‰è£…æˆ‘ä»¬éœ€è¦çš„ç½‘ç«™å»ºç«‹çš„æ¡†æ¶
brew install hugo  é€‰æ‹©ç®¡ç†blogçš„ä½ç½®,ä¾‹å¦‚æˆ‘çš„æ¡Œé¢ï¼Œç„¶åå»ºç«‹æ–°é¡¹ç›®e.g myblog, å¹¶è¿›å…¥blogæ–‡ä»¶å¤¹
cd ~/Desktop hugo new site myblog cd myblog  å°è¯•å»ºç«‹å†…å®¹ä¸ºâ€hello world&amp;rdquo;çš„post, å°†å…¶å‘½åä¸ºmyfirst_post.md
hugo new posts/myfirst_post echo &amp;quot;hello world&amp;quot; &amp;gt; content/posts/myfirst_post.</description>
    </item>
    
    <item>
      <title>Amazing Optimizer until 2019.3</title>
      <link>https://mmy12580.github.io/posts/optimizers/</link>
      <pubDate>Fri, 25 Jan 2019 11:18:47 -0500</pubDate>
      
      <guid>https://mmy12580.github.io/posts/optimizers/</guid>
      <description>Introduction As a researcher, most time of my job is to build an approriate AI prototype for specific tasks. To achieve a satisfactoring result, an expected large amount of work i.e tuning hyper-parameters, balancing data, augmentation etc are needed. One of the hyper-parameters has the most impactul effects on the results. Sometime, it is able to determine the direction of research or indutrial deployment, which is learning rate The learning rate is one of the most important things need to be taken care of.</description>
    </item>
    
    <item>
      <title>Activation is important!</title>
      <link>https://mmy12580.github.io/posts/activation/</link>
      <pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mmy12580.github.io/posts/activation/</guid>
      <description>Overview: Activation functions play a crucial rule in neural networks because they are the nonlinearities which have been attributed to the success story of deep learning. At present, the most popular activation functions are ReLU and its extended work such as LReLU, PReLu, ELU, SELU, and CReLU etc. However, none of them is guaranteed to perform better then others in all applications, so it becomes fundamental to understand their advantages and disadvantages in order to achieve better performances in specific applications.</description>
    </item>
    
  </channel>
</rss>