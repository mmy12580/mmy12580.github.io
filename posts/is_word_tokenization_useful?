---
title: "Is Chinese Word Segmentation Necessary?"
date: 2019-05-23T10:27:31-04:00
draft: true
---


# Introduction


I have been working on NLP for more than a year and half, especially on Chinese due to the work at **Leafy AI Lab**. Segmenting a chunk of text into words is usually the first step of processing Chinese text, and it is often used for so many downstream tasks such as sequential labeling, lexical analysis, dependency parsing, an so on. **However**, I found an interesting phenomenon while I was conducting research on Named Entity Recognition (**NER**).

